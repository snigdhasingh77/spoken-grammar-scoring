{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":120126,"databundleVersionId":14369730,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:10:56.323273Z","iopub.execute_input":"2025-12-17T07:10:56.323536Z","iopub.status.idle":"2025-12-17T07:10:57.379339Z","shell.execute_reply.started":"2025-12-17T07:10:56.323515Z","shell.execute_reply":"2025-12-17T07:10:57.378537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q torch torchaudio ffmpeg-python","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:10:57.380835Z","iopub.execute_input":"2025-12-17T07:10:57.381191Z","iopub.status.idle":"2025-12-17T07:12:07.376803Z","shell.execute_reply.started":"2025-12-17T07:10:57.381172Z","shell.execute_reply":"2025-12-17T07:12:07.375902Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q \\\n    language-tool-python==2.7.1 \\\n    protobuf==3.20.3 \\\n    transformers==4.38.2 \\\n    sentencepiece","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:12:07.377877Z","iopub.execute_input":"2025-12-17T07:12:07.378245Z","iopub.status.idle":"2025-12-17T07:12:19.834093Z","shell.execute_reply.started":"2025-12-17T07:12:07.378219Z","shell.execute_reply":"2025-12-17T07:12:19.833270Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom transformers import pipeline\nimport language_tool_python\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import pearsonr\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:12:19.835125Z","iopub.execute_input":"2025-12-17T07:12:19.835330Z","iopub.status.idle":"2025-12-17T07:12:42.866039Z","shell.execute_reply.started":"2025-12-17T07:12:19.835308Z","shell.execute_reply":"2025-12-17T07:12:42.865450Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/shl-intern-hiring-assessment-2025\"\n\nTRAIN_CSV = f\"{DATA_PATH}/dataset/csvs/train.csv\"\nTEST_CSV  = f\"{DATA_PATH}/dataset/csvs/test.csv\"\n\nTRAIN_AUDIO_DIR = f\"{DATA_PATH}/dataset/audios/train\"\nTEST_AUDIO_DIR  = f\"{DATA_PATH}/dataset/audios/test\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:12:42.867709Z","iopub.execute_input":"2025-12-17T07:12:42.868206Z","iopub.status.idle":"2025-12-17T07:12:42.872314Z","shell.execute_reply.started":"2025-12-17T07:12:42.868187Z","shell.execute_reply":"2025-12-17T07:12:42.871549Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv(TRAIN_CSV)\ntest_df  = pd.read_csv(TEST_CSV)\n\ntrain_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:12:42.873122Z","iopub.execute_input":"2025-12-17T07:12:42.873433Z","iopub.status.idle":"2025-12-17T07:12:42.929907Z","shell.execute_reply.started":"2025-12-17T07:12:42.873414Z","shell.execute_reply":"2025-12-17T07:12:42.929329Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(6,4))\nplt.hist(train_df[\"label\"], bins=10)\nplt.xlabel(\"Grammar Score\")\nplt.ylabel(\"Count\")\nplt.title(\"Distribution of Grammar Scores\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:12:42.930567Z","iopub.execute_input":"2025-12-17T07:12:42.930763Z","iopub.status.idle":"2025-12-17T07:12:43.164633Z","shell.execute_reply.started":"2025-12-17T07:12:42.930747Z","shell.execute_reply":"2025-12-17T07:12:43.164009Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"asr = pipeline(\n    \"automatic-speech-recognition\",\n    model=\"openai/whisper-small\",\n    device=-1\n)\n\ndef transcribe_audio(filename, split=\"train\"):\n    audio_dir = TRAIN_AUDIO_DIR if split == \"train\" else TEST_AUDIO_DIR\n\n    if not filename.endswith(\".wav\"):\n        filename = filename + \".wav\"\n\n    audio_path = os.path.join(audio_dir, filename)\n    return asr(audio_path)[\"text\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:12:43.165365Z","iopub.execute_input":"2025-12-17T07:12:43.165639Z","iopub.status.idle":"2025-12-17T07:12:56.246625Z","shell.execute_reply.started":"2025-12-17T07:12:43.165607Z","shell.execute_reply":"2025-12-17T07:12:56.246094Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_grammar_features(text, tool=None):\n    if not text or len(text.strip()) == 0:\n        return {\n            \"num_errors\": 0,\n            \"word_count\": 0,\n            \"error_rate\": 0.0\n        }\n\n    errors = 0\n    if tool is not None:\n        try:\n            matches = tool.check(text)\n            errors = len(matches)\n        except Exception:\n            errors = 0  # API failure fallback\n\n    words = len(text.split())\n\n    return {\n        \"num_errors\": errors,\n        \"word_count\": words,\n        \"error_rate\": errors / max(words, 1)\n    }\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:12:56.247407Z","iopub.execute_input":"2025-12-17T07:12:56.247921Z","iopub.status.idle":"2025-12-17T07:12:56.252455Z","shell.execute_reply.started":"2025-12-17T07:12:56.247896Z","shell.execute_reply":"2025-12-17T07:12:56.251712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom tqdm import tqdm\nUSE_CACHED_FEATURES = True\n\nCACHE_PATH = \"cached_train_features.csv\"\n\nif USE_CACHED_FEATURES and os.path.exists(CACHE_PATH):\n    print(\"Loading cached grammar features...\")\n    feature_df = pd.read_csv(CACHE_PATH)\n\nelse:\n    print(\"Extracting grammar features (first-time run)...\")\n\n    import language_tool_python\n    tool = language_tool_python.LanguageToolPublicAPI('en-US')\n\n    features = []\n\n    for _, row in tqdm(train_df.iterrows(), total=len(train_df)):\n        try:\n            text = transcribe_audio(row[\"filename\"], split=\"train\")\n        except Exception:\n            text = \"\"\n\n        feats = extract_grammar_features(text, tool)\n        feats[\"label\"] = row[\"label\"]\n        features.append(feats)\n\n    feature_df = pd.DataFrame(features)\n    feature_df.to_csv(CACHE_PATH, index=False)\n    print(\"Grammar features cached successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T09:18:26.370189Z","iopub.execute_input":"2025-12-17T09:18:26.370908Z","iopub.status.idle":"2025-12-17T09:18:26.381893Z","shell.execute_reply.started":"2025-12-17T09:18:26.370874Z","shell.execute_reply":"2025-12-17T09:18:26.381142Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = feature_df.drop(columns=[\"label\"])\ny = feature_df[\"label\"]\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T09:21:38.278401Z","iopub.execute_input":"2025-12-17T09:21:38.278957Z","iopub.status.idle":"2025-12-17T09:21:38.287003Z","shell.execute_reply.started":"2025-12-17T09:21:38.278919Z","shell.execute_reply":"2025-12-17T09:21:38.286212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = RandomForestRegressor(\n    n_estimators=300,\n    random_state=42\n)\n\nmodel.fit(X_train, y_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T09:21:38.288114Z","iopub.execute_input":"2025-12-17T09:21:38.288397Z","iopub.status.idle":"2025-12-17T09:21:38.659053Z","shell.execute_reply.started":"2025-12-17T09:21:38.288381Z","shell.execute_reply":"2025-12-17T09:21:38.658446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_preds = model.predict(X_train)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, train_preds))\n\nprint(\"Training RMSE:\", train_rmse)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T09:21:38.659924Z","iopub.execute_input":"2025-12-17T09:21:38.660188Z","iopub.status.idle":"2025-12-17T09:21:38.682732Z","shell.execute_reply.started":"2025-12-17T09:21:38.660164Z","shell.execute_reply":"2025-12-17T09:21:38.682004Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_preds = model.predict(X_val)\n\nval_rmse = np.sqrt(mean_squared_error(y_val, val_preds))\npearson_corr, _ = pearsonr(y_val, val_preds)\n\nprint(\"Validation RMSE:\", val_rmse)\nprint(\"Pearson Correlation:\", pearson_corr)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T09:21:38.684533Z","iopub.execute_input":"2025-12-17T09:21:38.684804Z","iopub.status.idle":"2025-12-17T09:21:38.701934Z","shell.execute_reply.started":"2025-12-17T09:21:38.684787Z","shell.execute_reply":"2025-12-17T09:21:38.701205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(6,4))\nplt.scatter(y_val, val_preds)\nplt.xlabel(\"True Score\")\nplt.ylabel(\"Predicted Score\")\nplt.title(\"True vs Predicted Grammar Scores\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T09:21:38.702762Z","iopub.execute_input":"2025-12-17T09:21:38.703059Z","iopub.status.idle":"2025-12-17T09:21:38.843262Z","shell.execute_reply.started":"2025-12-17T09:21:38.703036Z","shell.execute_reply":"2025-12-17T09:21:38.842669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_features = []\n\nfor filename in test_df[\"filename\"]:\n    try:\n        text = transcribe_audio(filename, split=\"test\")\n    except Exception as e:\n        print(f\"ASR failed for test file {filename}: {e}\")\n        text = \"\"\n\n    feats = extract_grammar_features(text)\n    test_features.append(feats)\n\ntest_feature_df = pd.DataFrame(test_features)\n\ntest_predictions = model.predict(test_feature_df)\n\nsubmission = pd.DataFrame({\n    \"filename\": test_df[\"filename\"],\n    \"label\": test_predictions\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T09:21:38.843926Z","iopub.execute_input":"2025-12-17T09:21:38.844181Z","iopub.status.idle":"2025-12-17T10:01:27.436512Z","shell.execute_reply.started":"2025-12-17T09:21:38.844154Z","shell.execute_reply":"2025-12-17T10:01:27.435878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_df.shape)\nprint(test_df.shape)\nprint(train_df.columns)\nprint(test_df.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T10:01:27.437285Z","iopub.execute_input":"2025-12-17T10:01:27.437540Z","iopub.status.idle":"2025-12-17T10:01:27.442406Z","shell.execute_reply.started":"2025-12-17T10:01:27.437524Z","shell.execute_reply":"2025-12-17T10:01:27.441538Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nsample = train_df[\"filename\"].iloc[10]\nprint(sample)\nprint(os.path.exists(os.path.join(TRAIN_AUDIO_DIR, sample + \".wav\")))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T10:01:27.443206Z","iopub.execute_input":"2025-12-17T10:01:27.443486Z","iopub.status.idle":"2025-12-17T10:01:27.464445Z","shell.execute_reply.started":"2025-12-17T10:01:27.443460Z","shell.execute_reply":"2025-12-17T10:01:27.463725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range(10):\n    fname = train_df[\"filename\"].iloc[i]\n    try:\n        text = transcribe_audio(fname, split=\"train\")\n        print(f\"{fname}: SUCCESS →\", text[:80])\n    except Exception as e:\n        print(f\"{fname}: ASR FAILED → {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T10:01:27.465194Z","iopub.execute_input":"2025-12-17T10:01:27.465384Z","iopub.status.idle":"2025-12-17T10:03:10.139021Z","shell.execute_reply.started":"2025-12-17T10:01:27.465368Z","shell.execute_reply":"2025-12-17T10:03:10.138318Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_text = \"I has a pen. She go to school yesterday.\"\nprint(extract_grammar_features(test_text))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T10:03:10.141342Z","iopub.execute_input":"2025-12-17T10:03:10.141600Z","iopub.status.idle":"2025-12-17T10:03:10.951632Z","shell.execute_reply.started":"2025-12-17T10:03:10.141579Z","shell.execute_reply":"2025-12-17T10:03:10.950879Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_df.isna().sum()\nfeature_df.describe()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T10:03:10.952946Z","iopub.execute_input":"2025-12-17T10:03:10.953291Z","iopub.status.idle":"2025-12-17T10:03:10.969272Z","shell.execute_reply.started":"2025-12-17T10:03:10.953266Z","shell.execute_reply":"2025-12-17T10:03:10.968578Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train RMSE:\", train_rmse)\nprint(\"Val RMSE:\", val_rmse)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T10:03:10.971000Z","iopub.execute_input":"2025-12-17T10:03:10.971260Z","iopub.status.idle":"2025-12-17T10:03:10.980062Z","shell.execute_reply.started":"2025-12-17T10:03:10.971244Z","shell.execute_reply":"2025-12-17T10:03:10.979377Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission[\"label\"].min(), submission[\"label\"].max()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T10:03:10.980705Z","iopub.execute_input":"2025-12-17T10:03:10.981021Z","iopub.status.idle":"2025-12-17T10:03:10.994358Z","shell.execute_reply.started":"2025-12-17T10:03:10.981005Z","shell.execute_reply":"2025-12-17T10:03:10.993824Z"}},"outputs":[],"execution_count":null}]}